model:
  clip:
    pretrained_model: ViT-B/32
  clap:
    pretrained_model: Wav2Vec2.0
  fusion:
    fusion_method: concat
  query_encoder:
    architecture: transformer

training:
  batch_size: 16
  epochs: 100
  learning_rate: 0.0001
  weight_decay: 0.01
